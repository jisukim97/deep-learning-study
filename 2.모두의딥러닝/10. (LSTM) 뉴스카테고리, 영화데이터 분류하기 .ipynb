{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 활용(3)\n",
    "### : 시퀀스 배열로 다루는 순환 신경망 ( RNN : Recurrent Neural Network )\n",
    "* 여러 개의 데이터가 순서대로 입력됐을 때 앞서 입력받은 데이터를 잠시 기억해 놓는 방법\n",
    "* 그 중에서도 LSTM(Long Short Term Memory)를 가장 널리 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> LSTM을 이용한 로이터 뉴스 카테고리 분류하기\n",
    "-> 긴 텍스트를 읽고 이 데이터가 어떤 의미를 가졌는지 카테고리로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#데이터 준비하기\n",
    "from keras.datasets import reuters\n",
    "\n",
    "(X_train, Y_train),(X_test, Y_test) = reuters.load_data(num_words=1000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 카테고리\n",
      "8982 학습용 뉴스 기사\n",
      "2246 테스트용 뉴스 기사\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "#데이터 확인\n",
    "import numpy as np\n",
    "category = np.max(Y_train)+1\n",
    "print(category,\"카테고리\")\n",
    "print(len(X_train),'학습용 뉴스 기사')\n",
    "print(len(X_test),'테스트용 뉴스 기사')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 기사의 단어 수 맞추기 \n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 [==============================] - 20s 224ms/step - loss: 2.5946 - accuracy: 0.3480 - val_loss: 2.4158 - val_accuracy: 0.3620\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 19s 207ms/step - loss: 2.1542 - accuracy: 0.4447 - val_loss: 1.9335 - val_accuracy: 0.5031\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 19s 207ms/step - loss: 1.8775 - accuracy: 0.5157 - val_loss: 1.8553 - val_accuracy: 0.5467\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 19s 208ms/step - loss: 1.8656 - accuracy: 0.5342 - val_loss: 1.8045 - val_accuracy: 0.5552\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 19s 210ms/step - loss: 1.7142 - accuracy: 0.5609 - val_loss: 1.7286 - val_accuracy: 0.5744\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 19s 206ms/step - loss: 1.6477 - accuracy: 0.5796 - val_loss: 1.6778 - val_accuracy: 0.5815\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 18s 203ms/step - loss: 1.6015 - accuracy: 0.5897 - val_loss: 1.6410 - val_accuracy: 0.5824\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 19s 206ms/step - loss: 1.5573 - accuracy: 0.6022 - val_loss: 1.5925 - val_accuracy: 0.6042\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 1.5047 - accuracy: 0.6208 - val_loss: 1.5706 - val_accuracy: 0.6158\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 18s 199ms/step - loss: 1.4356 - accuracy: 0.6425 - val_loss: 1.5110 - val_accuracy: 0.6211\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 1.3683 - accuracy: 0.6574 - val_loss: 1.4676 - val_accuracy: 0.6447\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 18s 199ms/step - loss: 1.3133 - accuracy: 0.6689 - val_loss: 1.4354 - val_accuracy: 0.6500\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 1.2478 - accuracy: 0.6882 - val_loss: 1.4073 - val_accuracy: 0.6523\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 18s 201ms/step - loss: 1.2015 - accuracy: 0.6965 - val_loss: 1.3933 - val_accuracy: 0.6536\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 1.1536 - accuracy: 0.7063 - val_loss: 1.3195 - val_accuracy: 0.6616\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 18s 199ms/step - loss: 1.0927 - accuracy: 0.7219 - val_loss: 1.2649 - val_accuracy: 0.6776\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 1.0383 - accuracy: 0.7384 - val_loss: 1.2540 - val_accuracy: 0.6821\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 18s 202ms/step - loss: 0.9934 - accuracy: 0.7531 - val_loss: 1.2373 - val_accuracy: 0.6923\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 19s 206ms/step - loss: 0.9539 - accuracy: 0.7656 - val_loss: 1.2112 - val_accuracy: 0.7030\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 17s 194ms/step - loss: 0.9139 - accuracy: 0.7737 - val_loss: 1.1970 - val_accuracy: 0.7110\n",
      "71/71 [==============================] - 2s 31ms/step - loss: 1.1970 - accuracy: 0.7110\n",
      "\n",
      "Test Accuracy: 0.7110\n"
     ]
    }
   ],
   "source": [
    "#모델의 설정\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000,100))\n",
    "model.add(LSTM(100,activation='tanh'))\n",
    "model.add(Dense(46, activation = 'softmax'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#모델 실행\n",
    "history = model.fit(x_train, y_train, batch_size = 100, epochs=20, validation_data = (x_test, y_test))\n",
    "\n",
    "print(\"\\nTest Accuracy: %.4f\"%(model.evaluate(x_test,y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM과 CNN의 조합으로 영화리뷰 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.4485 - accuracy: 0.7742 - val_loss: 0.3673 - val_accuracy: 0.8382\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.2961 - accuracy: 0.8751 - val_loss: 0.3338 - val_accuracy: 0.8562\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.2540 - accuracy: 0.8944 - val_loss: 0.3249 - val_accuracy: 0.8597\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.2164 - accuracy: 0.9157 - val_loss: 0.3286 - val_accuracy: 0.8556\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.1800 - accuracy: 0.9332 - val_loss: 0.3483 - val_accuracy: 0.8555\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.3483 - accuracy: 0.8555\n",
      "\n",
      " Test Accuracy: 0.8555\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#seed값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#학습, 테스트 데이터 준비 및 전처리\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "\n",
    "#모델 설정 밑 컴파일\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000,100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(55))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#모델 실행\n",
    "history=model.fit(x_train, y_train, batch_size=100, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "print('\\n Test Accuracy: %.4f'%(model.evaluate(x_test, y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
