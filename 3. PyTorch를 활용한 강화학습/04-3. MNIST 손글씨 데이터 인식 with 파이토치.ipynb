{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#fetch_mldata -> openml로 변경되었지만 똑같은 데이터 형식 유지하기 (솜장 블로그 참고)\n",
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1] \n",
    "    mnist.data[:60000] = mnist.data[reorder_train] \n",
    "    mnist.target[:60000] = mnist.target[reorder_train] \n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000] \n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]\n",
    "\n",
    "try: \n",
    "    from sklearn.datasets import fetch_openml \n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True) \n",
    "    mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings \n",
    "    sort_by_target(mnist) # fetch_openml() returns an unsorted dataset \n",
    "except ImportError: \n",
    "    from sklearn.datasets import fetch_mldata \n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 이미지 데이터의 레이블은 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 데이터와 레이블 데이터 분리, 정규화\n",
    "\n",
    "X = mnist.data / 255 #0~255의 값을 [0,1]구간의 값으로 정규화\n",
    "y = mnist.target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#예시로 하나의 데이터를 시각화\n",
    "plt.imshow(X[7000].reshape(28,28), cmap = 'gray')\n",
    "print(\"이 이미지 데이터의 레이블은 {:.0f}\".format(y[7000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DataLoader 생성\n",
    "- train data, test data로 분할\n",
    "- numpy배열을 tensor객체로 변환\n",
    "- dataset 객체 생성\n",
    "- dataset 객체를 DataLoader 객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6:1비율로  트레인 데이터, 테스트 데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=1/7, random_state = 0)\n",
    "\n",
    "#데이터를 파이토치 텐서로 변환\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train) #정수형 데이터는 longTensor 객체로\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "#데이터와 정답 레이블을 묶어 Dataset으로 만듦\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "#미니배치 크기를 지정해 DataLoader객체로 변환\n",
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True) #신경망의 결합가중치를 한번에 수정할 때 사용되는 데이터 건수 == 배치 사이즈\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False) #테스트 데이터는 굳이 섞을 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#케라스 스타일\n",
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(28*28*1,100))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2',nn.Linear(100,100))\n",
    "model.add_module('relu2',nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(100,10))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 오차함수 및 최적화 기법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#오차 함수\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#최적화 함수 for가중치 학습\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습 및 추론 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train() #신경망을 학습 모드로 전환\n",
    "    \n",
    "    #데이터 로더에서 미니배치를 하나씩 꺼내 학습 수행\n",
    "    for data, targets in loader_train:\n",
    "        optimizer.zero_grad() #경사를 0으로 초기화\n",
    "        outputs = model(data) #데이터 입력하고 출력을 계산\n",
    "        loss = loss_fn(outputs, targets) \n",
    "        loss.backward() #오차 역전파\n",
    "        optimizer.step() #역전파 값으로 가중치 수정\n",
    "    \n",
    "    print(\"epoch{}: 완료\\n\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval() #신경망을 테스트 모드로 전환\n",
    "    correct = 0\n",
    "    \n",
    "    #데이터로더에서 미니 배치 하나씩 꺼내 테스트\n",
    "    with torch.no_grad(): #미분 없이\n",
    "        for data, targets in loader_test:\n",
    "            \n",
    "            outputs = model(data) #데이터 입력 후 출력 계산\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1) #확률이 가장 높은 레이블은 무엇\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum() #정답과 일치하면 정답 카운트 ++\n",
    "    \n",
    "    #accuracy\n",
    "    data_num = len(loader_test.dataset) #총 데이터 수\n",
    "    print(\"\\n 테스트 데이터 예측 정확도: {}/{} ({:.0f}%)\\n\".format(correct, data_num, 100.*correct/data_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.학습 및 추론 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 테스트 데이터 예측 정확도: 908/10000 (9%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#학습 전, 테스트 데이터 정확도 측정\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0: 완료\n",
      "\n",
      "epoch1: 완료\n",
      "\n",
      "epoch2: 완료\n",
      "\n",
      "\n",
      " 테스트 데이터 예측 정확도: 9615/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    train(epoch)\n",
    "    \n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
